{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comfy UI through remote ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (1176572259.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"files.simpleDialog.enable\": true\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "\"files.simpleDialog.enable\": true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv comfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: comfyScriptsactivate.bat: command not found\n"
     ]
    }
   ],
   "source": [
    "!comfy\\Scripts\\activate.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl\n",
      "Collecting torch==2.1.0+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp39-cp39-linux_x86_64.whl (2200.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm0:04\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.16.0+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp39-cp39-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.1.0+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xformers\n",
      "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl (211.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.1.0+cu121) (3.0)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.1.0+cu121) (4.4.0)\n",
      "Collecting triton==2.1.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.0+cu121) (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.1.0+cu121) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch==2.1.0+cu121) (2023.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.16.0+cu121) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.16.0+cu121) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.16.0+cu121) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.1.0+cu121) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.16.0+cu121) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.16.0+cu121) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision==0.16.0+cu121) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision==0.16.0+cu121) (2.8)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, torch, xformers, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu116\n",
      "    Uninstalling torchvision-0.13.1+cu116:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu116\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.12.1+cu116\n",
      "    Uninstalling torchaudio-0.12.1+cu116:\n",
      "      Successfully uninstalled torchaudio-0.12.1+cu116\n",
      "Successfully installed mpmath-1.3.0 sympy-1.12 torch-2.1.0+cu121 torchaudio-2.1.0+cu121 torchvision-0.16.0+cu121 triton-2.1.0 xformers-0.0.22.post7+cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 --extra-index-url https://download.pytorch.org/whl xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu121)\n",
      "Collecting torchsde\n",
      "  Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.25.1\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.0\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.8.3)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.9.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (4.64.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (5.9.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Collecting trampoline>=0.1.2\n",
      "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from torchsde->-r requirements.txt (line 2)) (1.23.4)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (18.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.3.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 6)) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Installing collected packages: trampoline, safetensors, fsspec, einops, huggingface-hub, torchsde, tokenizers, accelerate, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "Successfully installed accelerate-0.24.1 einops-0.7.0 fsspec-2023.10.0 huggingface-hub-0.19.4 safetensors-0.4.0 tokenizers-0.15.0 torchsde-0.2.6 trampoline-0.1.2 transformers-4.35.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** ComfyUI start up time: 2023-11-17 03:33:31.262040\n",
      "\n",
      "Prestartup times for custom nodes:\n",
      "   0.0 seconds: /notebooks/brain-decoding/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "\n",
      "Total VRAM 24248 MB, total RAM 45140 MB\n",
      "xformers version: 0.0.22.post7+cu118\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA RTX A5000 : cudaMallocAsync\n",
      "VAE dtype: torch.bfloat16\n",
      "Using xformers cross attention\n",
      "### Loading: ComfyUI-Manager (V1.0.1)\n",
      "### ComfyUI Revision: 1697 [7e3fe3ad] | Released on '2023-11-16'\n",
      "\n",
      "Import times for custom nodes:\n",
      "   0.1 seconds: /notebooks/brain-decoding/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
      "   0.3 seconds: /notebooks/brain-decoding/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "\n",
      "Starting server\n",
      "\n",
      "To see the GUI go to: http://127.0.0.1:8188\n",
      "got prompt\n",
      "ERROR:root:Failed to validate prompt for output 9:\n",
      "ERROR:root:* CheckpointLoaderSimple 4:\n",
      "ERROR:root:  - Bad linked input, must be a length-2 list of [node_id, slot_index]: ckpt_name\n",
      "ERROR:root:Output will be ignored\n",
      "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
      "^C\n",
      "\n",
      "Stopped server\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API [example from Comfy UI github]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ComfyUI-Custom-Scripts'...\n",
      "remote: Enumerating objects: 1215, done.\u001b[K\n",
      "remote: Counting objects: 100% (318/318), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 1215 (delta 254), reused 268 (delta 220), pack-reused 897\u001b[K\n",
      "Receiving objects: 100% (1215/1215), 347.67 KiB | 3.51 MiB/s, done.\n",
      "Resolving deltas: 100% (706/706), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/brain-decoding/ComfyUI\n"
     ]
    }
   ],
   "source": [
    "cd /notebooks/brain-decoding/ComfyUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 1346, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1285, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1331, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1280, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1040, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 946, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 844, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 832, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/brain-decoding/ComfyUI/script_examples/basic_api_example.py\", line 118, in <module>\n",
      "    queue_prompt(prompt)\n",
      "  File \"/notebooks/brain-decoding/ComfyUI/script_examples/basic_api_example.py\", line 107, in queue_prompt\n",
      "    request.urlopen(req)\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 214, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 517, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 534, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 494, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 1375, in http_open\n",
      "    return self.do_open(http.client.HTTPConnection, req)\n",
      "  File \"/usr/lib/python3.9/urllib/request.py\", line 1349, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 111] Connection refused>\n"
     ]
    }
   ],
   "source": [
    "!python script_examples/basic_api_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "print(\"work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pinging 127.0.0.1 with 32 bytes of data:\n",
      "Reply from 127.0.0.1: bytes=32 time<1ms TTL=128\n",
      "Reply from 127.0.0.1: bytes=32 time<1ms TTL=128\n",
      "Reply from 127.0.0.1: bytes=32 time<1ms TTL=128\n",
      "Reply from 127.0.0.1: bytes=32 time<1ms TTL=128\n",
      "\n",
      "Ping statistics for 127.0.0.1:\n",
      "    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),\n",
      "Approximate round trip times in milli-seconds:\n",
      "    Minimum = 0ms, Maximum = 0ms, Average = 0ms\n"
     ]
    }
   ],
   "source": [
    "!ping 127.0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Comfy UI [from github]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/brain-decoding/ComfyUI\n"
     ]
    }
   ],
   "source": [
    "cd brain-decoding/ComfyUI\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " README.md\t\t\t     lvae_recon_710.png\n",
      " brain-decoding\t\t\t     quick_start_pytorch.ipynb\n",
      " color\t\t\t\t     quick_start_pytorch_images\n",
      " color_diffusion_pytorch_model.bin  'reconstruction_[testing_canny].ipynb'\n",
      " config.json\t\t\t     test.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ComfyUI'...\n",
      "remote: Enumerating objects: 8354, done.\u001b[K\n",
      "remote: Counting objects: 100% (2619/2619), done.\u001b[K\n",
      "remote: Compressing objects: 100% (343/343), done.\u001b[K\n",
      "remote: Total 8354 (delta 2391), reused 2320 (delta 2275), pack-reused 5735\u001b[K\n",
      "Receiving objects: 100% (8354/8354), 3.52 MiB | 17.06 MiB/s, done.\n",
      "Resolving deltas: 100% (5605/5605), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/comfyanonymous/ComfyUI.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API [img2img workflow sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: path: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python api_comfyui-img2img.py -w <path>\\ComfyUI-workflow-recolor-api.json -i <path>\\image-grey.jpg -o outputPrefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /notebooks/brain-decoding/ComfyUI/api_comfyui-img2img.py -w <path>/notebooks/brain-decoding/comfyui-api-part1-basic-workflow/workflow_api.json -i <path>/notebooks/lvae_recon_710.png -o outputPrefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API [Yushan = basic workflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad parameter 8188.\n"
     ]
    }
   ],
   "source": [
    "!ping 127.0.0.1 -p 8188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Desktop\\brain-decoding\\comfyui-api-part1-basic-workflow\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/lenovo/Desktop/brain-decoding/comfyui-api-part1-basic-workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dumped\n",
      "requesting url connect\n",
      "data dumped\n",
      "requesting url connect\n",
      "data dumped\n",
      "requesting url connect\n",
      "data dumped\n",
      "requesting url connect\n"
     ]
    }
   ],
   "source": [
    "!python basic_workflow_api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API [Yushan = our img2img workflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Desktop\\brain-decoding\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/lenovo/Desktop/brain-decoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib import request, parse\n",
    "import random\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sends a prompt workflow to the specified URL \n",
    "# (http://127.0.0.1:8188/prompt) and queues it on the ComfyUI server\n",
    "# running at that address.\n",
    "def queue_prompt(prompt_workflow):\n",
    "    p = {\"prompt\": prompt_workflow}\n",
    "    data = json.dumps(p).encode('utf-8')\n",
    "    print(\"data dumped\")\n",
    "    req =  request.Request(\"http://127.0.0.1:8188/prompt\", data=data)\n",
    "    print(\"requesting url connect\")\n",
    "    request.urlopen(req)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read workflow api data from file and convert it into dictionary \n",
    "# assign to var prompt_workflow\n",
    "prompt_workflow = json.load(open('workflow_api_sd_1_5_t2i_color_cn_depth.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give some easy-to-remember names to the nodes\n",
    "chkpoint_loader_node = prompt_workflow[\"4\"]\n",
    "prompt_pos_node = prompt_workflow[\"6\"]\n",
    "prompt_neg_node = prompt_workflow[\"7\"]\n",
    "ksampler_node = prompt_workflow[\"3\"]\n",
    "save_image_node = prompt_workflow[\"9\"]\n",
    "load_init_image_node = prompt_workflow[\"10\"]\n",
    "load_depth_image_node = prompt_workflow[\"22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint that we want. \n",
    "# make sure the path is correct to avoid 'HTTP Error 400: Bad Request' errors\n",
    "chkpoint_loader_node[\"inputs\"][\"ckpt_name\"] = \"v1-5-pruned-emaonly.safetensors\"\n",
    "prompt_workflow[\"14\"][\"inputs\"][\"control_net_name\"] = \"control_v11f1p_sd15_depth_fp16.safetensors\"\n",
    "prompt_workflow[\"13\"][\"inputs\"][\"control_net_name\"] = \"t2iadapter_color_sd14v1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvae_data = {}\n",
    "with open(\"C:/Users/lenovo/Desktop/brain-decoding/recon_979.png\", mode='rb') as file:\n",
    "    img = file.read()\n",
    "lvae_data['img'] = base64.encodebytes(img).decode('utf-8')\n",
    "\n",
    "depth_data = {}\n",
    "with open(\"C:/Users/lenovo/Desktop/brain-decoding/depth_979.png\", mode='rb') as file:\n",
    "    img = file.read()\n",
    "depth_data['img'] = base64.encodebytes(img).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed in KSampler node \n",
    "ksampler_node[\"inputs\"][\"seed\"] = random.randint(1, 18446744073709551614)\n",
    "ksampler_node[\"inputs\"][\"steps\"] = 10\n",
    "\n",
    "#inputs\n",
    "# set the text prompt for positive CLIPTextEncode node\n",
    "prompt_pos_node[\"inputs\"][\"text\"] = \"a giraffe standing around some dry grass and branches, cinematic photo, highly detailed, realistic\"\n",
    "prompt_neg_node[\"inputs\"][\"text\"] = \"anime, cartoon, graphic, text, painting, drawing, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured, impressionist, noisy, blurry\"\n",
    "\n",
    "#load images\n",
    "#json.dumps(lvae_data['img'])\n",
    "#json.dumps(depth_data['img'])\n",
    "load_init_image_node[\"inputs\"][\"image\"] = \"recon_979.png\"\n",
    "load_depth_image_node[\"inputs\"][\"image\"] = \"depth_979.png\"\n",
    "\n",
    "save_image_node[\"inputs\"][\"filename_prefix\"] = \"output_979\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dumped\n",
      "requesting url connect\n"
     ]
    }
   ],
   "source": [
    "# everything set, add entire workflow to queue.\n",
    "queue_prompt(prompt_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual attempt at using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url=f'http://127.0.0.1:8188/prompt', json=payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
